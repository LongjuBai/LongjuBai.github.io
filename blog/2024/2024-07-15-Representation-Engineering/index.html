<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h3 id="introduction-to-representation-engineering-repe">Introduction to Representation Engineering (RepE)</h3> <p>Representation Engineering (RepE) offers a complementary research paradigm for understanding and controlling Large Language Models (LLMs), running parallel to Mechanistic Interpretability (MI). While <strong>MI</strong> primarily operates at the level of circuits—such as attention heads, pathways, and neurons—<strong>RepE</strong> focuses on the <strong>representational spaces</strong> (the inner activations at each layer). Both approaches aim to increase the transparency and control of LLM behavior.</p> <p>Some potential applications of Representation Engineering include:</p> <ul> <li> <strong>Jailbreaking</strong>: Identifying and controlling prompts that bypass model restrictions.</li> <li> <strong>Motion Forecasting</strong>: Predicting movement patterns based on representation spaces.</li> </ul> <p>For more insights, refer to these resources:</p> <ul> <li><a href="https://vgel.me/posts/representation-engineering/" rel="external nofollow noopener" target="_blank">Representation Engineering Blog by vgel.me</a></li> <li><a href="https://www.alignmentforum.org/posts/3ghj8EuKzwD3MQR5G/an-introduction-to-representation-engineering-an-activation#Activation_Patching" rel="external nofollow noopener" target="_blank">An Introduction to Representation Engineering on Alignment Forum</a></li> </ul> <hr> <h3 id="structure-of-the-repe-paper">Structure of the RepE Paper</h3> <p>The RepE paper is divided into two primary sections: <strong>Representation Reading</strong> and <strong>Representation Control</strong>.</p> <hr> <h3 id="part-1-representation-reading">Part 1: Representation Reading</h3> <p><strong>Representation Reading</strong> aims to identify a <strong>reading vector</strong> in the activation space that aligns with a specific high-level concept, behavior, or function. This vector, also known as a <strong>concept vector</strong>, helps detect or control certain concepts within the model’s internal representation. Below are the key steps to derive this vector:</p> <ol> <li> <p><strong>Design Contrastive Inputs</strong>: Create inputs that stimulate the model’s inner activity regarding specific concepts, often using pairwise contrasts (e.g., harmful vs. harmless, honest vs. dishonest).</p> </li> <li> <p><strong>Feed Inputs and Collect Activations</strong>: Pass the designed inputs into the model and collect activations (representations) from specific layers (often from the last token’s representation).</p> </li> <li> <p><strong>Apply Dimensionality Reduction and Clustering</strong>: Use techniques like <strong>Principal Component Analysis (PCA)</strong>, <strong>K-Means</strong>, or other supervised or unsupervised methods to find a linear vector that effectively separates the two contrasting classes (e.g., harmful vs. harmless).</p> </li> </ol> <h4 id="usage-of-the-reading-vector">Usage of the Reading Vector</h4> <p>To make predictions, compute the <strong>dot product</strong> between the concept vector and a target representation vector. This indicates whether the target vector contains the concept. Alternatively, you can scan activations across all layers to assess the strength of a specific concept throughout the model.</p> <hr> <h3 id="part-2-representation-control">Part 2: Representation Control</h3> <p><strong>Representation Control</strong> (also called <strong>Representation Steering</strong>) involves modifying the activations of the LLM during a forward pass to influence its behavior. This section explores ways to control the internal representations of concepts and functions within the model.</p> <h4 id="step-1-choose-a-controller">Step 1: Choose a Controller</h4> <p>There are several options for selecting a controller:</p> <ul> <li> <strong>Reading Vector</strong>: The vector extracted from the Representation Reading process.</li> <li> <strong>Contrast Vector</strong>: Derived from a pair of contrastive prompts during inference. The difference between the representations of these prompts forms a Contrast Vector.</li> <li> <strong>Low-Rank Adapter</strong>: Fine-tune low-rank adapters linked to the model, applying a specific loss function to representations.</li> </ul> <h4 id="step-2-choose-an-intervention-method">Step 2: Choose an Intervention Method</h4> <p>After selecting a controller, choose an operator to apply to the model’s inner activations:</p> <ul> <li> <strong>Linear Combination</strong>: Blend vectors linearly to steer activations.</li> <li> <strong>Piece-Wise Operation</strong>: Apply different transformations to parts of the vector.</li> <li> <strong>Projection</strong>: Project onto or away from certain concept directions.</li> <li> <strong>Adapter</strong>: Use fine-tuned adapters to influence representations based on the desired concept or function.</li> </ul> <hr> <p>This blog post provides an overview of <strong>Representation Engineering</strong> as a structured approach to understanding and guiding LLM behaviors. By working within representational spaces rather than specific neurons or pathways, RepE opens new possibilities for transparent and controllable AI.</p> </body></html>